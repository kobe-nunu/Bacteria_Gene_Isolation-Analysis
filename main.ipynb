{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatics project - part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this part we designed and wrote a program the does the following:\n",
    "\n",
    "<br>\n",
    "\n",
    "Given a set of COG-spelled genomes S, where each genome is segmented into segments such that each segment could contain one or more operons, and given parameters Q, l and an unknown COG X, finds all strings c of length l that are conserved in at least q of the genoomes in the database S, such the our unknown COg appears at least once in c.\n",
    "\n",
    "<br>\n",
    "\n",
    "The COG chosen by us is COG 0673.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initializing parameters and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog = '0673'\n",
    "q = 5\n",
    "l = 5 # we tool all strings c where  2 <= |c| <= 10 to start with and to get more information for the biological analysis */\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Searching for all words with our cog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_words(database, cog):\n",
    "    lst = []\n",
    "    for index, row in database.iterrows():\n",
    "        if cog in row['E']:\n",
    "            lst.append([row['E'], row['B']])\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > Search_words goes through every single line on our database and gathers all instances where our cog is in. <br>\n",
    " We also record each organism where the line was presented for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_bact = pd.read_csv(\".\\cog_words_bac.csv\") #loading the first database\n",
    "words_plasm = pd.read_csv(\".\\cog_words_plasmid.csv\") #loading the second database\n",
    "\n",
    "bact_lst = search_words(words_bact, cog)\n",
    "plasm_lst = search_words(words_plasm, cog)\n",
    "full_lst = bact_lst + plasm_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the \"heaviest\" function in our program, since it is looping over the entire database and looking for instances of our cog. <br>\n",
    "The time complexity is $O(|DATABASE|*|COG|)$, and since |cog|=4 which is constant the time complexity overall is $O(|DATABASE|)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Encoding our list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our list is now made of 2-items lists: in the first item(<full_lst[i][0]>) there is a word which contains our COG, and the second item(<full_lst[i][1]>) contatins the organism that had this word in it's genome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['505\\t0079\\t0673\\t3475\\t1211\\t0451\\tX\\tX\\t0463\\t2244\\t1209\\t1088\\t1091\\t0463\\t1898\\t1088\\t', 'NC_016077']\n",
      "505\t0079\t0673\t3475\t1211\t0451\tX\tX\t0463\t2244\t1209\t1088\t1091\t0463\t1898\t1088\t\n",
      "NC_016077\n"
     ]
    }
   ],
   "source": [
    "print(full_lst[8])\n",
    "print(full_lst[8][0])\n",
    "print(full_lst[8][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our words are made out of 3-4 digits \"letters\" which are seperated by tabs. on the next stage we want to extract all substrings of each words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Due to the sturcture of the words, it may be inconvenient to loop through the words and letters, so we decided to enconde each letter(which is actually an integer) into it's ascii character. <br>\n",
    "- There are over 10,000 characters which are encoded in ascii, so each COG will be mapped to exactly one character in an injective way. <br>\n",
    "- That way we know we won't harm our words, and after removing the tabs we will get words just like we know them, which are easy to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(words):\n",
    "    coded_lst = []\n",
    "    for word in words:\n",
    "        organism = word[1]\n",
    "        word = word[0]\n",
    "        index = 0\n",
    "        right = 0\n",
    "        str = ''\n",
    "        while right != -1:\n",
    "            if word[index] == 'X':\n",
    "                str += 'X'\n",
    "                right = get_next(word, right)\n",
    "                index = right\n",
    "                continue\n",
    "            right = get_next(word, right)\n",
    "            ascii = int(word[index:right - 1])\n",
    "            index = right\n",
    "            char = chr(ascii)\n",
    "            str += char\n",
    "        coded_lst.append([str, organism])\n",
    "    return coded_lst\n",
    "\n",
    "def get_next(str, index):\n",
    "    len1 = len(str)\n",
    "    while str[index] != '\\t':\n",
    "        index += 1\n",
    "    index += 1\n",
    "    return index if index < len1 else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > The words might not be distinguishable to human eyes, but the computer can tell the differences due to the way Strings are stored in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ǹOʡඓһǃXXǏ\\u08c4ҹруǏݪl', 'NC_016077']\n"
     ]
    }
   ],
   "source": [
    "coded_lst = encode(full_lst)\n",
    "print(coded_lst[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Getting all substrings with our COG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our list is ready to work with, we want to get all substrings in length K which contains our cog. <br>\n",
    "\n",
    "- *we won't forget to count each appearance of each substring, since multiple appearances might tell us something about this particular string.* <br>\n",
    "\n",
    "- *we also won't forget to keep the organism in which each substring was in, for the next section.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subs(str, counter, length, organism):\n",
    "    subs = []\n",
    "    for i in range(len(str)):\n",
    "        sub = str[i: i + length]\n",
    "        if len(sub) == length and chr(int(cog)) in sub:\n",
    "            if sub in counter:\n",
    "                counter[sub][0] += 1\n",
    "                counter[sub][2].add(organism)\n",
    "            else:\n",
    "                counter[sub] = [1, len(sub), set()]\n",
    "                counter[sub][2].add(organism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple program to find substrings. For a String with size s, we want to generate all substrings with length k which contains our COG.<br>\n",
    "\n",
    "This is being done in $O(k*|S|+|S|) = O(k*|S|)$ for each string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = {}\n",
    "for j in range(len(coded_lst)): #loop over every string in our list\n",
    "    for i in range(2, 11): #get all strings with lengths 2 to 10\n",
    "        get_subs(coded_lst[j][0], counter, i, coded_lst[j][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From this point onwards, we will refer to our coded_lst size as \"n\". <br>\n",
    "\n",
    ">we won't forget that n <<< |DATABASE|\n",
    "\n",
    "That's why the process of getting all subs is **************TODO - explain about time complexity and dictionary count************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Filtering according to q parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all substrings kept in a dictionary, it's time to keep only the substrings which appeared on at least q different organisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we take a look on our dictionary, we can see it's made of keys, which are our substrings, and values, which are now 3-items lists:\n",
    "- counter['sub'][0] contains the number of times we witnessed this particular sub. <br>\n",
    "\n",
    "- counter['sub'][1] contains the length of the substring\n",
    "\n",
    "- counter['sub'][2] contains a set of all the genomes where this substring appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, {'NC_013209'}]\n"
     ]
    }
   ],
   "source": [
    "print(counter['ॢʡÑ\\x14'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As you can see, despite the fact this substring seems to in length 7, it is actually has only 4 cogs in it. \n",
    "\n",
    "\n",
    "> We can also see it appears in only one COG. since our q value is 5, we want to filter it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = {k: v for k, v in counter.items() if len(v[2]) > q} # filtering according to q value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print('ॢʡÑ\\x14' in counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have filtered out the unnecessary strings, we can decode our strings again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(counter):\n",
    "    dict = {}\n",
    "    for key in counter.keys():\n",
    "        res = ''\n",
    "        for char in key:\n",
    "            code = str(ord(char))\n",
    "            code = (4 - len(code))*'0'+code\n",
    "            res += code\n",
    "            res += '\\t'\n",
    "        dict[res] = counter[key]\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = decode(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment and run the next line of code in order to filter and get only subs with length l\n",
    "#counter = {k: v for k, v in counter.items() if v[1] == l}\n",
    "#however, we won't do this for now, since we want all substrings with length 2 to 10 for a more complete biological analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Issuing a csv report with all the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(counter, orient='index').reset_index()\n",
    "df = df.rename(columns={'index': 'word', 1: 'length', 0: 'occurrences', 2: 'organisms'})\n",
    "s = 'report_' + cog + '.csv'\n",
    "df.to_csv(f\"./{s}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see a csv report with all the information is available in the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For better presentation, it is recommended to download the csv file and open it on your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus stage: analysing the csv file for a better representation of our results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all our relevant data ready, we want to present each word made of cogs and align it with their known functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(cog):\n",
    "    df = pd.read_csv(f\"./report_{cog}.csv\")\n",
    "    new_df = df[df['length'] >= 5] #we want to take only long strings with our cog\n",
    "    results = []\n",
    "    for index, row in new_df.iterrows(): #splitting the tabs from our strings\n",
    "        cogs = row['word'][:-1]\n",
    "        cog_list = cogs.split('\\t')\n",
    "        results.append([cog_list, row['occurrences']])\n",
    "        \n",
    "    cog_table = pd.read_csv(\"./cog_info_table.csv\") #this table contains the functionality of each cog, so we are loading it for now.\n",
    "\n",
    "    to_remove = []\n",
    "    for result in results: #now we want to remove all sequences which are substrings of other sequences. This is for better visualisation\n",
    "        for result2 in results:\n",
    "            if all(elem in result[0] for elem in result2[0]) and result[0] != result2[0] and result[0] not in to_remove:\n",
    "                to_remove.append(result2[0])\n",
    "                break\n",
    "\n",
    "    results = [x for x in results if x[0] not in to_remove]\n",
    "    with open(f\"./final_report_{cog}.txt\", \"w\") as report:\n",
    "        for lst in results:\n",
    "            lst_to_str = '\\t'.join(lst[0]) + '\\t'\n",
    "            ls = str(lst[0]) + f\"    ||||||||     num of occurances: {lst[1]}\\n\"\n",
    "            flag = False\n",
    "            for cog2 in lst[0]:\n",
    "                d = cog_table.loc[cog_table['A'] == 'COG{}'.format(cog2), 'D'].values\n",
    "                e = cog_table.loc[cog_table['A'] == 'COG{}'.format(cog2), 'E'].values\n",
    "                s = d + '|' + e\n",
    "                try:\n",
    "                    if 'Translation' in s[0] or 'translation' in s[0]:\n",
    "                        i = 0\n",
    "                        flag = True\n",
    "                    else:\n",
    "                        ls = ls + s + '\\n'\n",
    "                except IndexError:\n",
    "                    print(f'cog_{cog2} is faulty')\n",
    "                    ls = ls + f'Unknown_{cog2}\\n'\n",
    "            if not flag:\n",
    "                report.write(''.join(ls))\n",
    "    report.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(cog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now you can open \"final_report_{cog}\" in the directory and start your biological analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
